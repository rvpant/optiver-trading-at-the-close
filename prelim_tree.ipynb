{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94cf436-9d8e-4532-9eee-43652a3d1e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier #Second is for data size >10k. CLASSIFICATION.\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor #as above. REGRESSION.\n",
    "# import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e41be-6ac0-45d4-ad1b-87831da1ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_top_20k.csv')\n",
    "df = df[df.columns.tolist()[1:]] #Drops the duplicated index values in the first column.\n",
    "df.dropna(subset=['target'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867d44ef-2d6c-4f15-98db-b0dc248844c8",
   "metadata": {},
   "source": [
    "#### Some basic notes on the column definitions, units, etc:\n",
    "- imbalance_size is defined as the \"amount unmatched at the current reference price (in USD)\"\n",
    "- imbalance_buy_sell_flag gives the DIRECTION of the auction imbalance\n",
    "- reference_price is the price at which paired shares are maximized, the imbalance is minimized and the distance from the bid-ask midpoint is minimized (in that order). **What does this mean exactly?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d4f3a-02cd-49c3-9403-9c2b044dd56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_arr = [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]\n",
    "stock_id_list = np.arange(200)\n",
    "weights_df = pd.DataFrame({'stock_id':stock_id_list, 'weight':weight_arr})\n",
    "df = df.merge(weights_df, how='left', on='stock_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae1309-37b8-400e-8447-882f6a2c3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell to explore the above loaded df if needed without disturbing what is below.\n",
    "\n",
    "# df[~df['far_price'].isna()]\n",
    "\n",
    "# test = df.groupby(['stock_id']).rolling(3)['bid_price'].mean().fillna(method='bfill')\n",
    "# df['ewmas_3'] = np.zeros(len(df))\n",
    "# df['ewmas_3'] = np.where(df['stock_id']==0, test, df['ewmas_3'])\n",
    "# print(df.groupby('stock_id').rolling(1)['bid_price'].mean()[0].head(20))\n",
    "# test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfa02b-387d-4e38-8edb-bcfaf259e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['stock_id']==0].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e80eed-749a-49c6-a4f5-279485e8a8f1",
   "metadata": {},
   "source": [
    "#### Next cell will be adding some BASIC features to the data as manual (domain-specific) augmentation. \n",
    "TBD: how to incorporate formal kernel methods if that is of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512c951-4ebf-4d80-88d2-59d4ece94984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Add basics like categorical target (for classification tree), book skew + other simple data transforms.\n",
    "df['book_skew'] = np.log(df['bid_size']/df['ask_size'])\n",
    "df['target_cat'] = np.where(df['target'] < 0, -1, np.where(df['target'] > 0, 1, 0)) #should we make this binary?\n",
    "\n",
    "#Add some moving-average style transformations of important variables.\n",
    "ewma_windows = [3,5,10]\n",
    "ewma_cols = ['imbalance_size', 'book_skew', 'bid_price', 'ask_price']\n",
    "for w in ewma_windows:\n",
    "    for col in ewma_cols:\n",
    "        df[f'ewmas_{col}_{w}'] = np.zeros(len(df))\n",
    "        for id in df['stock_id'].unique():\n",
    "            ma = df.groupby(['stock_id']).rolling(w)[col].mean().fillna(method='bfill').loc[id] #This is a little sketchy, maybe worth changing?\n",
    "            # df[f'ewmas_{col}_{w}'] = np.where(df['stock_id']==id, ma, df[f'ewmas_{col}_{w}'])\n",
    "            df[f'ewmas_{col}_{w}'][ma.index] = ma\n",
    "        # print(f'ewmas_{col}_{w}', np.sum(df[f'ewmas_{col}_{w}']==0))\n",
    "\n",
    "\n",
    "\n",
    "# df[['book_skew', 'ewmas_book_skew_5', 'bid_price', 'ask_price', 'ewmas_bid_price_5', 'ewmas_ask_price_5', \"stock_id\", 'date_id']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c0d00-4b1a-4733-9685-4a5564722b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = df[df['ewmas_imbalance_size_3']== 0][['stock_id', 'date_id', 'imbalance_size', 'ewmas_imbalance_size_3']]\n",
    "# test['stock_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1cc5ab-994e-4c08-b9cc-e6fdad16deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Derive the train/test params for our toy model.\n",
    "print(df.time_id.unique()) #gonna use up to 40 for training and the rest for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4475c8-bf37-4452-a18b-9db2a1b9d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the train-test split.\n",
    "X_train = df[df['time_id'] <=40].drop(columns=['target', 'target_cat'])\n",
    "X_train = X_train.fillna(1e-9) #For imputing NaN values. Does this value make a big difference to performance?\n",
    "X_test = df[df['time_id'] >40].drop(columns=['target', 'target_cat'])\n",
    "X_test = X_test.fillna(1e-9) #See above.\n",
    "print(\"Xtrain length\", len(X_train)); print(\"Xtest length\", len(X_test))\n",
    "y_train = df[df['time_id'] <=40]['target']\n",
    "y_test = df[df['time_id'] >40]['target']\n",
    "\n",
    "#Filter for final feature set.\n",
    "features = [c for c in df.columns if not c in ['stock_id','date_id','seconds_in_bucket','target_cat', 'target']]\n",
    "print(\"Number of features used: \", len(features))\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a985dd-07dd-44e2-8fb3-d56070cdcb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit classifier.\n",
    "interesting_cols = ['seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'time_id', 'weight', 'book_skew']\n",
    "clf = GradientBoostingRegressor(loss='absolute_error', learning_rate=0.05, n_estimators=1000, verbose=1, random_state=42)\n",
    "clf.fit(X_train[interesting_cols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9e604-4ab3-4fdc-893a-5d25e77014f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run prediction.\n",
    "y_pred = clf.predict(X_test[interesting_cols])\n",
    "prediction_mae = np.linalg.norm(y_pred-y_test,ord=1)/len(y_pred)\n",
    "print(prediction_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f33e350-a452-413a-b5b1-5f5aa6e2766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fits a classifier with early stopping and min impurity criterion for limiting overfitting.\n",
    "#Should we include cost-complexity pruning as well?\n",
    "clf2 = GradientBoostingRegressor(loss='absolute_error', learning_rate=0.05, n_estimators=1000, verbose=1, random_state=42,\n",
    "                                validation_fraction=0.2, n_iter_no_change=3, min_impurity_decrease=0.1)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da902d1-8d7a-43a1-a2e8-760532810c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction using the limited classifier.\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "prediction2_mae = np.linalg.norm(y_pred2-y_test,ord=1)/len(y_pred2)\n",
    "print(prediction2_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90818ab6-f8fb-4f3c-bf9e-6dbb7a26b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(clf.feature_names_in_, height=clf.feature_importances_)\n",
    "plt.figure(figsize=(50,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydotplus import graph_from_dot_data\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2048dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(\n",
    "    clf2.estimators_[1,0],\n",
    "    out_file=None, filled=True, rounded=True,\n",
    "    special_characters=True,\n",
    "    proportion=True, impurity=False, # enable them if you want\n",
    "    feature_names=clf.feature_names_in_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713cd306",
   "metadata": {},
   "source": [
    "Get the 20th tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527af22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_from_dot_data(dot_data)\n",
    "png = graph.create_png()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path('./tree_20.png').write_bytes(png)\n",
    "# Display\n",
    "Image(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee58cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e984a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.estimators_[1,0].predict(X_test)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
